# spark_data_integration

Ce sous projet Scala Spark concerne le TP 1.



Je dois faire ce TP (exercice) en Big Data en Scala.

Je suis au TP 2 : Du datalake vers un datawarehouse.

Voici la consigne :

```text
‣ L’entreprise du CAC40 fictive a finalement pu trouver une finalité amenant à utiliser les fichiers parquets
dormants dans le Datalake. Nous allons devoir commencer à récupérer ces fichiers parquets qui sera intégré
vers un nouveau service de base donnée postgresql jouant le rôle de Data Warehouse.

‣ Vous pouvez concevoir un scripting Scala / Spark, prêt à être mis en production afin de récupérer un fichier
parquet et permettant de réaliser une ingestion de données vers postgresql Data Warehouse
```

`Main.scala` :

```scala

```

`docker-file.yml` :

```yml

```

Je veux donc récupérer les fichiers `.parquet` de Minio vers  postgresql Data Warehouse.